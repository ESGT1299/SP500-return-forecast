{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018378ce",
   "metadata": {},
   "source": [
    "# ðŸ¤– 04_deep_learning.ipynb  \n",
    "## Neural Nets: MLP & LSTM\n",
    "\n",
    "### 1. Objective  \n",
    "Teach a **Multi-Layer Perceptron (MLP)** and a **Long Short-Term Memory (LSTM)** to predict daily returns.\n",
    "\n",
    "> _Like first drawing a still picture (MLP), then making a short cartoon (LSTM) that remembers what happened a few frames ago._\n",
    "\n",
    "---\n",
    "\n",
    "### 2. MLP\n",
    "\n",
    "- **Input:** todayâ€™s `rsi` and `macd`  \n",
    "- **Architecture:** Dense(64) â†’ Dropout â†’ Dense(32) â†’ Dense(1)  \n",
    "- **Train:** 30 epochs, early stop if no improvement.  \n",
    "- **Evaluate:** **MAE_mlp**, **RÂ²_mlp**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. LSTM\n",
    "\n",
    "- **Sequence length:** 5 days  \n",
    "- **Input shape:** (5 days Ã— 2 features)  \n",
    "- **Architecture:** LSTM(50) â†’ Dense(1)  \n",
    "- **Train & evaluate** similarly.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Save Models & Test Data  \n",
    "- Store `mlp_model/`, `lstm_model/` folders.  \n",
    "- Save `X_test.npy`, `y_test.npy` (for MLP) and `X_te2.npy`, `y_te2.npy` (for LSTM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ad1a6",
   "metadata": {},
   "source": [
    "## Reload features & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921f0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path().resolve().parent\n",
    "df = pd.read_csv(root/\"data\"/\"processed\"/\"features.csv\",\n",
    "                 index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "X = df[[\"rsi\",\"macd\"]].values\n",
    "y = df[\"return\"].values\n",
    "\n",
    "split = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a1365",
   "metadata": {},
   "source": [
    "## Build and train an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64f72a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31/31 [==============================] - 1s 14ms/step - loss: 40.5287 - mae: 4.9176 - val_loss: 2.0718 - val_mae: 1.2130\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 13.8775 - mae: 2.8594 - val_loss: 0.6053 - val_mae: 0.7178\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.7604 - mae: 2.0186 - val_loss: 0.1105 - val_mae: 0.1793\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.5795 - mae: 1.4408 - val_loss: 0.0584 - val_mae: 0.2184\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.7172 - mae: 1.2814 - val_loss: 0.0332 - val_mae: 0.1494\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8716 - mae: 1.0353 - val_loss: 0.0592 - val_mae: 0.2122\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.5846 - mae: 0.9579 - val_loss: 0.0317 - val_mae: 0.1245\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2141 - mae: 0.8322 - val_loss: 0.0331 - val_mae: 0.1286\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0054 - mae: 0.7691 - val_loss: 0.1300 - val_mae: 0.3034\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.9228 - mae: 0.7312 - val_loss: 0.0464 - val_mae: 0.1412\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.7628 - mae: 0.6656 - val_loss: 0.0632 - val_mae: 0.1833\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.7131 - mae: 0.6392 - val_loss: 0.0362 - val_mae: 0.1189\n",
      "MLP MAE: 0.11887\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define MLP\n",
    "mlp = Sequential([\n",
    "    layers.Input(shape=(2,)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "mlp.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Train\n",
    "history = mlp.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test,y_test),\n",
    "    epochs=30,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "mae_mlp = mlp.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"MLP MAE: {mae_mlp:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7607ed",
   "metadata": {},
   "source": [
    "## Build and train an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09e0f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 27ms/step - loss: 0.0310 - mae: 0.1096 - val_loss: 0.0088 - val_mae: 0.0656\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0037 - val_mae: 0.0379\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 9.0481e-04 - mae: 0.0210 - val_loss: 0.0024 - val_mae: 0.0297\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 5.3067e-04 - mae: 0.0165 - val_loss: 0.0016 - val_mae: 0.0239\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 3.7877e-04 - mae: 0.0142 - val_loss: 0.0014 - val_mae: 0.0218\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 2.9906e-04 - mae: 0.0130 - val_loss: 0.0011 - val_mae: 0.0193\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 2.5599e-04 - mae: 0.0119 - val_loss: 9.1643e-04 - val_mae: 0.0179\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 2.3687e-04 - mae: 0.0114 - val_loss: 9.8068e-04 - val_mae: 0.0182\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 2.1916e-04 - mae: 0.0113 - val_loss: 9.5691e-04 - val_mae: 0.0180\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8887e-04 - mae: 0.0104 - val_loss: 7.8761e-04 - val_mae: 0.0169\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.7569e-04 - mae: 0.0101 - val_loss: 8.6916e-04 - val_mae: 0.0166\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.6478e-04 - mae: 0.0097 - val_loss: 8.0823e-04 - val_mae: 0.0172\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7389e-04 - mae: 0.0101 - val_loss: 7.6355e-04 - val_mae: 0.0164\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5767e-04 - mae: 0.0095 - val_loss: 8.4702e-04 - val_mae: 0.0155\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5286e-04 - mae: 0.0093 - val_loss: 8.0039e-04 - val_mae: 0.0154\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4385e-04 - mae: 0.0090 - val_loss: 8.5586e-04 - val_mae: 0.0150\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4001e-04 - mae: 0.0090 - val_loss: 7.8080e-04 - val_mae: 0.0147\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5098e-04 - mae: 0.0094 - val_loss: 7.3498e-04 - val_mae: 0.0145\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3543e-04 - mae: 0.0089 - val_loss: 8.0422e-04 - val_mae: 0.0148\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3852e-04 - mae: 0.0089 - val_loss: 9.7770e-04 - val_mae: 0.0183\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5373e-04 - mae: 0.0095 - val_loss: 7.0959e-04 - val_mae: 0.0138\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.4910e-04 - mae: 0.0093 - val_loss: 7.9288e-04 - val_mae: 0.0147\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5128e-04 - mae: 0.0094 - val_loss: 7.8625e-04 - val_mae: 0.0142\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.2886e-04 - mae: 0.0086 - val_loss: 7.2149e-04 - val_mae: 0.0139\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4224e-04 - mae: 0.0091 - val_loss: 8.1259e-04 - val_mae: 0.0147\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5959e-04 - mae: 0.0098 - val_loss: 7.9576e-04 - val_mae: 0.0144\n",
      "LSTM MAE: 0.01439\n"
     ]
    }
   ],
   "source": [
    "# Create sequences of 5 days\n",
    "timesteps = 5\n",
    "def make_seq(X, y, t):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(X)-t):\n",
    "        xs.append(X[i:i+t])\n",
    "        ys.append(y[i+t])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = make_seq(X, y, timesteps)\n",
    "split2 = int(len(X_seq)*0.8)\n",
    "X_tr2, X_te2 = X_seq[:split2], X_seq[split2:]\n",
    "y_tr2, y_te2 = y_seq[:split2], y_seq[split2:]\n",
    "\n",
    "# Define LSTM\n",
    "lstm = Sequential([\n",
    "    layers.LSTM(50, input_shape=(timesteps,2)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "lstm.compile(\"adam\",\"mse\",[\"mae\"])\n",
    "\n",
    "history2 = lstm.fit(\n",
    "    X_tr2, y_tr2,\n",
    "    validation_data=(X_te2,y_te2),\n",
    "    epochs=30,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "mae_lstm = lstm.evaluate(X_te2, y_te2, verbose=0)[1]\n",
    "print(f\"LSTM MAE: {mae_lstm:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febf7e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Antho\\OneDrive\\Documentos\\Santiago\\Finance project\\sp500_dl\\models\\mlp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Antho\\OneDrive\\Documentos\\Santiago\\Finance project\\sp500_dl\\models\\mlp_model\\assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Antho\\OneDrive\\Documentos\\Santiago\\Finance project\\sp500_dl\\models\\lstm_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Antho\\OneDrive\\Documentos\\Santiago\\Finance project\\sp500_dl\\models\\lstm_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MLP and LSTM saved to C:\\Users\\Antho\\OneDrive\\Documentos\\Santiago\\Finance project\\sp500_dl\\models\n"
     ]
    }
   ],
   "source": [
    "# --- save deep models & test data ---\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "root      = Path().resolve().parent\n",
    "model_dir = root / \"models\"\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the MLP\n",
    "mlp.save(model_dir / \"mlp_model\")\n",
    "\n",
    "# Save the LSTM\n",
    "lstm.save(model_dir / \"lstm_model\")\n",
    "\n",
    "# Save test arrays\n",
    "np.save(model_dir / \"X_test.npy\", X_test)\n",
    "np.save(model_dir / \"y_test.npy\", y_test)\n",
    "np.save(model_dir / \"X_te2.npy\",   X_te2)\n",
    "np.save(model_dir / \"y_te2.npy\",   y_te2)\n",
    "\n",
    "print(\"âœ… MLP and LSTM saved to\", model_dir)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp500_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
